{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "from freesound.utils.general import seed_everything, setup_tboard_writer\n",
    "from freesound.utils.lwlwrap import calculate_per_class_lwlrap\n",
    "from freesound.spec_augment import augment_spectrogram as augspecorig\n",
    "from freesound.imaug_seqs import imgaug_seqs_dict\n",
    "\n",
    "import bz2\n",
    "from freesound.preprocessor import Preprocessor\n",
    "import pylab as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "\n",
    "## PARAMS ##\n",
    "RUN_NAME = 'test'\n",
    "SEED = 2019\n",
    "PREPROCESSOR_CONFIG_NAME = 'default'\n",
    "RANDOM_VOLUME = 0.8\n",
    "SPEC_AUGMENT_PROB = 0.25\n",
    "MIXUP_ALPHA = 0.3\n",
    "IMGAUG_SEQ = 'default'\n",
    "############\n",
    "\n",
    "preprocessor_config_path = 'config/preprocessing/{}.yaml'.format(PREPROCESSOR_CONFIG_NAME)\n",
    "augment_spectrogram = lambda x: augspecorig(x, RANDOM_VOLUME, SPEC_AUGMENT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "tboard_writer, tboard_log_dir = setup_tboard_writer(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(os.environ['FS_INPUTS_BASE']) / 'freesound-audio-tagging-2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "    'test': dataset_dir / 'test.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_curated = pd.read_csv(csvs['train_curated'])\n",
    "df_train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "df_sample = pd.read_csv(csvs['sample_submission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_sample.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dummies(df):\n",
    "    y_train = df['labels'].str.get_dummies(sep=',').values.astype(np.float32)\n",
    "    assert y_train.shape[1] == 80\n",
    "    return y_train\n",
    "\n",
    "def df_to_x(df):\n",
    "    return df.fname.values\n",
    "\n",
    "def df_to_xy(df):\n",
    "    y = df_to_dummies(df)\n",
    "    x = df_to_x(df)\n",
    "    assert len(x) == len(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_to_xy(df_train_curated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_noisy, y_train_noisy = df_to_xy(df_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = df_to_x(df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wavnames = np.append(x_train, x_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took 168.1341371536255 seconds\n"
     ]
    }
   ],
   "source": [
    "preproc = Preprocessor(preprocessor_config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preproc.fill_cache(all_wavnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = imgaug_seqs_dict[IMGAUG_SEQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_img_and_label(pp, use_test_p=0.0):\n",
    "    if use_test_p > 0 and np.random.rand() < use_test_p:\n",
    "        # sample from test with no label\n",
    "        idx = np.random.randint(len(x_test))\n",
    "        return pp[x_test[idx]], y_train_noisy[0] * 0.0\n",
    "    idx = np.random.randint(len(x_train_noisy))\n",
    "    return pp[x_train_noisy[idx]], y_train_noisy[idx]\n",
    "        \n",
    "\n",
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, preproc, fnames, labels, seq, mixup_alpha, is_training,\n",
    "                 desired_length=128, no_labels=False, return_fnames=False, return_crop=False):\n",
    "        super().__init__()\n",
    "        self.preproc = preproc\n",
    "        self.fnames = fnames\n",
    "        self.labels = labels\n",
    "        self.seq = seq\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.is_training = is_training\n",
    "        self.desired_length = desired_length\n",
    "        self.no_labels = no_labels\n",
    "        self.return_fnames = return_fnames\n",
    "        self.return_crop = return_crop\n",
    "\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def crop_img(self, image):\n",
    "        time_dim = image.shape[1]\n",
    "        diff = time_dim - self.desired_length\n",
    "        if diff > 0:\n",
    "            crop = random.randint(0, diff)\n",
    "            self.last_crop = last_crop\n",
    "            image = image[:, crop:crop + self.desired_length]\n",
    "        elif diff < 0:\n",
    "            tmp = np.zeros([image.shape[0], self.desired_length, *image.shape[2:]],\n",
    "                           dtype=image.dtype)\n",
    "            start = random.randint(0, -diff)\n",
    "            self.last_crop = start\n",
    "            tmp[:, start:start + image.shape[1]] = image\n",
    "            image = tmp\n",
    "        return image\n",
    "    \n",
    "    def prep_img(self, image):\n",
    "        if self.is_training:\n",
    "            image = self.seq.augment_image(image)\n",
    "        image = self.transforms(image)\n",
    "        if self.is_training:\n",
    "            image = augment_spectrogram(image)\n",
    "        return image.div_(255)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preproc[self.fnames[idx]]\n",
    "        if image.shape[0] == 1:\n",
    "            image = np.tile(image, [3, 1, 1])\n",
    "        image = np.transpose(image, [1, 2, 0])\n",
    "        if not self.no_labels:\n",
    "            label = self.labels[idx]\n",
    "        image = self.crop_img(image)\n",
    "        if self.is_training and self.mixup_alpha:\n",
    "            mixup_p = np.random.beta(self.mixup_alpha + 1, self.mixup_alpha)\n",
    "            if mixup_p < 0.98:  # save compute when mixup barely has effect\n",
    "                oth_image, oth_label = get_noisy_img_and_label(self.preproc)\n",
    "                oth_image = self.crop_img(oth_image)\n",
    "                image = mixup_p * image + (1 - mixup_p) * image\n",
    "                image = image.round().astype(np.uint8)\n",
    "                label = label + (1 - mixup_p) * oth_label\n",
    "                label = np.clip(label, 0.0, 1.0)\n",
    "        image = self.prep_img(image)\n",
    "        ret = []\n",
    "        ret += [image]\n",
    "        if self.return_fnames:\n",
    "            ret += [self.fnames[idx]]\n",
    "        if self.return_crop:\n",
    "            ret += [self.last_crop]\n",
    "        if self.no_labels:\n",
    "            return tuple(ret)\n",
    "        ret += [torch.from_numpy(label).float()]\n",
    "        return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36'\n'",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
