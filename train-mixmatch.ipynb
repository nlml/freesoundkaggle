{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "from freesound.utils.general import seed_everything, setup_tboard_writer\n",
    "from freesound.utils.lwlwrap import calculate_per_class_lwlrap\n",
    "from freesound.spec_augment import augment_spectrogram as augspecorig\n",
    "from freesound.imaug_seqs import imgaug_seqs_dict\n",
    "from freesound.archis.large import Classifier\n",
    "\n",
    "import bz2\n",
    "from freesound.preprocessor import Preprocessor\n",
    "import pylab as plt\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'\n",
    "\n",
    "\n",
    "## PARAMS ##\n",
    "RUN_NAME = 'mixmatch_ALPHA_X=0.35'\n",
    "SEED = 2019\n",
    "PREPROCESSOR_CONFIG_NAME = 'default'\n",
    "RANDOM_VOLUME = 0.8\n",
    "SPEC_AUGMENT_PROB = 0.25\n",
    "MIXUP_ALPHA = 0.3\n",
    "IMGAUG_SEQ = 'default'\n",
    "BATCH_SIZE = 64\n",
    "LR = 3e-3\n",
    "LR_MIN = 1e-5\n",
    "T_MAX = 10\n",
    "NUM_EPOCHS = 300\n",
    "############\n",
    "\n",
    "preprocessor_config_path = 'config/preprocessing/{}.yaml'.format(PREPROCESSOR_CONFIG_NAME)\n",
    "augment_spectrogram = lambda x: augspecorig(x, RANDOM_VOLUME, SPEC_AUGMENT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "tboard_writer, tboard_log_dir = setup_tboard_writer(RUN_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(os.environ['FS_INPUTS_BASE']) / 'freesound-audio-tagging-2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "    'test': dataset_dir / 'test.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_curated = pd.read_csv(csvs['train_curated'])\n",
    "df_train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "df_sample = pd.read_csv(csvs['sample_submission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_sample.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dummies(df):\n",
    "    y_train = df['labels'].str.get_dummies(sep=',').values.astype(np.float32)\n",
    "    assert y_train.shape[1] == 80\n",
    "    return y_train\n",
    "\n",
    "def df_to_x(df):\n",
    "    return df.fname.values\n",
    "\n",
    "def df_to_xy(df):\n",
    "    y = df_to_dummies(df)\n",
    "    x = df_to_x(df)\n",
    "    assert len(x) == len(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_to_xy(df_train_curated)\n",
    "x_train_noisy, y_train_noisy = df_to_xy(df_train_noisy)\n",
    "x_test = df_to_x(df_sample)\n",
    "all_wavnames = np.append(x_train, x_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='5824' class='' max='24785', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      23.50% [5824/24785 06:25<20:56]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preproc = Preprocessor(preprocessor_config_path, dont_load=True)\n",
    "preproc.fill_cache(all_wavnames)\n",
    "# preproc.save_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_X = 0.35\n",
    "\n",
    "def mixup_mod(x1, x2, y1, y2, alpha):\n",
    "    # lambda is a reserved word in python, substituting by beta\n",
    "    beta = np.random.beta(alpha, alpha) \n",
    "    beta = np.amax([beta, 1 - beta])\n",
    "    x = beta * x1 + (1 - beta) * x2\n",
    "    y = beta * y1 + (1 - beta) * y2\n",
    "    return x, y\n",
    "\n",
    "def sharpen(x, T):\n",
    "    temp = x ** (1/T)\n",
    "    return temp / temp.sum(dim=1, keepdim=True)\n",
    "\n",
    "def label_guessing(model, ub, K):\n",
    "    with torch.no_grad():\n",
    "        was_training = model.training\n",
    "        model.eval()\n",
    "        pr = torch.sigmoid(model(ub))  # shape = [B*K, 80]\n",
    "        if was_training:\n",
    "            model.train()\n",
    "        return pr.view(K, pr.shape[0] // K, -1).mean(0).data\n",
    "\n",
    "def mixmatch_create_batch(x, y, Ux, model, T=0.5, alpha=0.75):\n",
    "    # (x, y) is labeled batch of shape [batch_size, ...]\n",
    "    # Ux should be unlabeled batch of shape [batch_size * K, ...] - K augmentations\n",
    "    K = Ux.shape[0] // x.shape[0]\n",
    "    avg_probs = label_guessing(model, Ux, K)\n",
    "    qb = sharpen(avg_probs, T)\n",
    "    Uy = qb.repeat([K, 1])\n",
    "    # Randon shuffle according to the paper\n",
    "    indices = np.arange(len(x) + len(Ux))\n",
    "    np.random.shuffle(indices)\n",
    "    # MixUp\n",
    "    Wx = torch.cat([Ux, x], dim=0)[indices]\n",
    "    Wy = torch.cat([Uy, y], dim=0)[indices]\n",
    "    X, p = mixup_mod(x, Wx[:len(x)], y, Wy[:len(x)], ALPHA_X)\n",
    "    U, q = mixup_mod(Ux, Wx[len(x):], Uy, Wy[len(x):], alpha)\n",
    "    return X, p, U, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = imgaug_seqs_dict[IMGAUG_SEQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "st = lambda aug, p=0.15: iaa.Sometimes(p, aug)  # noqa\n",
    "seq = iaa.Sequential([\n",
    "    st(iaa.Superpixels(p_replace=0.2, n_segments=(64, 256))),\n",
    "    st(iaa.CropAndPad(px=((-5, 5), (-20, 20), (-5, 5), (-20, 20)))),\n",
    "    st(iaa.GaussianBlur(sigma=(0.0, 1.5))),\n",
    "    st(iaa.PiecewiseAffine(scale=(0.005, 0.02))),\n",
    "    st(iaa.Add((-40, 40))),\n",
    "    st(iaa.AdditiveGaussianNoise(loc=0., scale=(0.1, 10)))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_img_and_label(pp):\n",
    "    idx = np.random.randint(len(x_train_noisy))\n",
    "    return pp[x_train_noisy[idx]], y_train_noisy[idx]\n",
    "        \n",
    "\n",
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, preproc, fnames, labels, seq, mixup_alpha=MIXUP_ALPHA, is_training=True,\n",
    "                 desired_length=128, no_labels=False, return_fnames=False, return_crop=False,\n",
    "                 no_unlabeled=False, K=2):\n",
    "        super().__init__()\n",
    "        self.preproc = preproc\n",
    "        self.fnames = fnames\n",
    "        self.labels = labels\n",
    "        self.seq = seq\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.is_training = is_training\n",
    "        self.desired_length = desired_length\n",
    "        self.no_labels = no_labels\n",
    "        self.return_fnames = return_fnames\n",
    "        self.return_crop = return_crop\n",
    "        self.no_unlabeled = no_unlabeled\n",
    "        self.K = K\n",
    "\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def preprep_img(self, image):\n",
    "        if image.shape[0] == 1:\n",
    "            image = np.tile(image, [3, 1, 1])\n",
    "        image = np.transpose(image, [1, 2, 0])\n",
    "        return image\n",
    "    \n",
    "    def crop_img(self, image):\n",
    "        time_dim = image.shape[1]\n",
    "        diff = time_dim - self.desired_length\n",
    "        if diff > 0:\n",
    "            crop = random.randint(0, diff)\n",
    "            self.last_crop = crop\n",
    "            image = image[:, crop:crop + self.desired_length]\n",
    "        elif diff < 0:\n",
    "            tmp = np.zeros([image.shape[0], self.desired_length, *image.shape[2:]],\n",
    "                           dtype=image.dtype)\n",
    "            start = random.randint(0, -diff)\n",
    "            self.last_crop = start\n",
    "            tmp[:, start:start + image.shape[1]] = image\n",
    "            image = tmp\n",
    "        return image\n",
    "    \n",
    "    def prep_img(self, image):\n",
    "        if self.is_training:\n",
    "            image = self.seq.augment_image(image)\n",
    "        image = self.transforms(image)\n",
    "        if self.is_training:\n",
    "            image = augment_spectrogram(image)\n",
    "        return image.div_(255)\n",
    "            \n",
    "    def _get_single_unlabled_img(self):\n",
    "        u, _ = get_noisy_img_and_label(self.preproc)\n",
    "        u = self.crop_img(self.preprep_img(u))\n",
    "        return u\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.preproc[self.fnames[idx]]\n",
    "        if not self.no_labels:\n",
    "            label = self.labels[idx]\n",
    "        image = self.crop_img(self.preprep_img(image))\n",
    "        if self.is_training and self.mixup_alpha:\n",
    "            mixup_p = np.random.beta(self.mixup_alpha + 1, self.mixup_alpha)\n",
    "            if mixup_p < 0.98:  # save compute when mixup barely has effect\n",
    "                oth_image, oth_label = get_noisy_img_and_label(self.preproc)\n",
    "                oth_image = self.crop_img(self.preprep_img(oth_image))\n",
    "                image = mixup_p * image + (1 - mixup_p) * oth_image\n",
    "                image = image.round().astype(np.uint8)\n",
    "                label = label + (1 - mixup_p) * oth_label\n",
    "                label = np.clip(label, 0.0, 1.0)\n",
    "        image = self.prep_img(image)\n",
    "        ret = []\n",
    "        ret += [image]\n",
    "        if self.return_fnames:\n",
    "            ret += [self.fnames[idx]]\n",
    "        if self.return_crop:\n",
    "            ret += [self.last_crop]\n",
    "        if self.no_labels:\n",
    "            return tuple(ret)\n",
    "        ret += [torch.from_numpy(label).float()]\n",
    "        if self.no_unlabeled:\n",
    "            return tuple(ret)\n",
    "        u = self._get_single_unlabled_img()\n",
    "        # multiple augmentations of same img crop\n",
    "        unlabeled_img = torch.cat([self.prep_img(u.copy()) for i in range(self.K)], 0)\n",
    "        ret += [unlabeled_img]\n",
    "        return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "test_batch_size = BATCH_SIZE\n",
    "lr = LR\n",
    "lr_min = LR_MIN\n",
    "t_max = T_MAX\n",
    "\n",
    "x_trn, x_val, y_trn, y_val = train_test_split(x_train, y_train, test_size=0.02, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FATTrainDataset(preproc, x_trn, y_trn, seq=seq, mixup_alpha=MIXUP_ALPHA, is_training=True)\n",
    "valid_dataset = FATTrainDataset(preproc, x_val, y_val, seq=None, is_training=False, no_unlabeled=True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "model = Classifier(num_classes=num_classes)\n",
    "# model = ClassifierPhase2(model)\n",
    "model = model.cuda()\n",
    "model = nn.DataParallel(model)\n",
    "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=lr_min)\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "num_epochs = NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_U = 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCEWithLogitsLoss().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interesting_epoch(epoch):\n",
    "    epoch = epoch + 1\n",
    "    if epoch // 10 % 2 == 1:\n",
    "        if epoch - (10 * (epoch // 10)) < 5:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "mb = master_bar(range(epoch, num_epochs))\n",
    "\n",
    "for epoch in mb:\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss_u, avg_loss = 0., 0.\n",
    "\n",
    "    for x_batch, y_batch, u_batch in progress_bar(train_loader, parent=mb):\n",
    "        x_batch = x_batch.cuda()\n",
    "        y_batch = y_batch.cuda()\n",
    "        h, w = u_batch.shape[-2:]\n",
    "        u_batch = u_batch.cuda().view(batch_size, 2, 3, h, w).permute(1, 0, 2, 3, 4).contiguous().view(-1, 3, h, w)\n",
    "        # u_batch is now [K * batch_size, 3, 128, 128]\n",
    "        K = u_batch.shape[0] // batch_size\n",
    "        X, p, U, q = mixmatch_create_batch(x_batch, y_batch, u_batch, model)\n",
    "        preds = model(X)\n",
    "        loss = criterion(preds, p)\n",
    "        preds_u = model(U)\n",
    "        loss_u = (1 / 80.) * mse(torch.sigmoid(preds_u), q)\n",
    "        loss_u *= LAMBDA_U\n",
    "        loss_total = loss + loss_u\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss.item() / len(train_loader)\n",
    "        avg_loss_u += loss_u.item() / len(train_loader)\n",
    "\n",
    "    do_val = is_interesting_epoch(epoch)\n",
    "\n",
    "    if do_val:\n",
    "        model.eval()\n",
    "        valid_preds = np.zeros((len(x_val), num_classes))\n",
    "        avg_val_loss = 0.\n",
    "\n",
    "        for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
    "            preds = model(x_batch.cuda()).detach()\n",
    "            loss = criterion(preds, y_batch.cuda())\n",
    "\n",
    "            preds = torch.sigmoid(preds)\n",
    "            valid_preds[i * test_batch_size: (i+1) * test_batch_size] = preds.cpu().numpy()\n",
    "\n",
    "            avg_val_loss += loss.item() / len(valid_loader)\n",
    "\n",
    "        score, weight = calculate_per_class_lwlrap(y_val, valid_preds)\n",
    "        lwlrap = (score * weight).sum()\n",
    "\n",
    "        if is_interesting_epoch(epoch):\n",
    "            savedir = str(tboard_log_dir).replace('tboard', 'ckpts')\n",
    "            if not os.path.exists(savedir):\n",
    "                os.makedirs(savedir)\n",
    "            torch.save(model.module.state_dict(), Path(savedir) / 'weight_epoch{}.pt'.format(epoch + 1))\n",
    "\n",
    "        tboard_writer.add_scalar('metrics/avg_val_loss', avg_val_loss, epoch + 1)\n",
    "        tboard_writer.add_scalar('metrics/val_lwlrap', lwlrap, epoch + 1)\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    tboard_writer.add_scalar('metrics/avg_train_loss', avg_loss, epoch + 1)\n",
    "    tboard_writer.add_scalar('metrics/avg_loss_u', avg_loss_u, epoch + 1)\n",
    "    tboard_writer.add_scalar('meta/lr', get_lr(optimizer), epoch + 1)\n",
    "    tboard_writer.add_scalar('meta/elapsed', elapsed, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36'\n'",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
