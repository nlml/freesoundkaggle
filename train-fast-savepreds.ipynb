{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from psutil import cpu_count\n",
    "\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from skmultilearn.model_selection import iterative_train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from fastprogress import master_bar, progress_bar\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "import tensorboardX\n",
    "\n",
    "from freesound.utils.general import seed_everything, setup_tboard_writer\n",
    "from freesound.utils.lwlwrap import calculate_per_class_lwlrap\n",
    "from freesound.spec_augment import augment_spectrogram as augspecorig\n",
    "from freesound.imaug_seqs import imgaug_seqs_dict\n",
    "from freesound.archis.large import Classifier\n",
    "\n",
    "import bz2\n",
    "from freesound.preprocessor import Preprocessor\n",
    "import pylab as plt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from shutil import rmtree\n",
    "import json\n",
    "from freesound.utils.general import hash_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0, 1'\n",
    "\n",
    "## PARAMS ##\n",
    "SEED = 2021\n",
    "NUM_VAL_PREDS_PER_EPOCH = 48\n",
    "PREPROCESSOR_CONFIG_NAME = 'tf_1024'\n",
    "RANDOM_VOLUME = 0.8\n",
    "SPEC_AUGMENT_PROB = 0.25\n",
    "MIXUP_ALPHA = 0.0\n",
    "IMGAUG_SEQ = 'default'\n",
    "BATCH_SIZE = 64\n",
    "LR = 3e-3\n",
    "LR_MIN = 1e-5\n",
    "T_MAX = 10\n",
    "NUM_EPOCHS = 300\n",
    "############\n",
    "\n",
    "preprocessor_config_path = 'config/preprocessing/{}.yaml'.format(PREPROCESSOR_CONFIG_NAME)\n",
    "augment_spectrogram = lambda x: augspecorig(x, RANDOM_VOLUME, SPEC_AUGMENT_PROB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hash params config and write to file\n",
    "params_dict = {}\n",
    "params_str = ['NUM_VAL_PREDS_PER_EPOCH', 'SEED', 'PREPROCESSOR_CONFIG_NAME', 'RANDOM_VOLUME', 'SPEC_AUGMENT_PROB',\n",
    "              'MIXUP_ALPHA', 'IMGAUG_SEQ', 'BATCH_SIZE', 'LR', 'LR_MIN', 'T_MAX', 'NUM_EPOCHS']\n",
    "for k in params_str:\n",
    "    params_dict[k] = eval(k)\n",
    "params_hash = hash_dict(params_dict)\n",
    "\n",
    "savedir = Path('ckpts') / params_hash\n",
    "os.makedirs(savedir)\n",
    "with open(savedir / 'config.json', 'w') as f:\n",
    "    json.dump(params_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(SEED)\n",
    "tboard_writer, tboard_log_dir = setup_tboard_writer(params_hash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_JOBS = cpu_count()\n",
    "os.environ['MKL_NUM_THREADS'] = str(N_JOBS)\n",
    "os.environ['OMP_NUM_THREADS'] = str(N_JOBS)\n",
    "DataLoader = partial(DataLoader, num_workers=N_JOBS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = Path(os.environ['FS_INPUTS_BASE']) / 'freesound-audio-tagging-2019'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvs = {\n",
    "    'train_curated': dataset_dir / 'train_curated.csv',\n",
    "    'train_noisy': dataset_dir / 'train_noisy.csv',\n",
    "    'sample_submission': dataset_dir / 'sample_submission.csv',\n",
    "    'test': dataset_dir / 'test.csv',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_curated = pd.read_csv(csvs['train_curated'])\n",
    "df_train_noisy = pd.read_csv(csvs['train_noisy'])\n",
    "df_sample = pd.read_csv(csvs['sample_submission'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_sample.columns[1:].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_dummies(df):\n",
    "    y_train = df['labels'].str.get_dummies(sep=',').values.astype(np.float32)\n",
    "    assert y_train.shape[1] == 80\n",
    "    return y_train\n",
    "\n",
    "def df_to_x(df):\n",
    "    return df.fname.values\n",
    "\n",
    "def df_to_xy(df):\n",
    "    y = df_to_dummies(df)\n",
    "    x = df_to_x(df)\n",
    "    assert len(x) == len(y)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = df_to_xy(df_train_curated)\n",
    "x_train_noisy, y_train_noisy = df_to_xy(df_train_noisy)\n",
    "x_train_all = np.concatenate([x_train, x_train_noisy], 0)\n",
    "y_train_all = np.concatenate([y_train, y_train_noisy], 0)\n",
    "x_test = df_to_x(df_sample)\n",
    "all_wavnames = np.append(x_train, x_train_noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading took 4.1961669921875e-05 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "                background: #F44336;\n",
       "            }\n",
       "        </style>\n",
       "      <progress value='4293' class='' max='24785', style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      17.32% [4293/24785 01:53<09:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/liam/freesoundkaggle/src/freesound/data_utils/audio_transforms_tf.py:55: RuntimeWarning: divide by zero encountered in log10\n",
      "  S = np.maximum(-80., 10 * np.log10(S + 1e-80) - 10 * 3.4)\n"
     ]
    }
   ],
   "source": [
    "preproc = Preprocessor(preprocessor_config_path)\n",
    "preproc.fill_cache(all_wavnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = imgaug_seqs_dict[IMGAUG_SEQ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noisy_img_and_label(pp):\n",
    "    idx = np.random.randint(len(x_train_noisy))\n",
    "    fname = x_train_noisy[idx]\n",
    "    return pp[fname], y_train_noisy[idx], fname\n",
    "        \n",
    "\n",
    "class FATTrainDataset(Dataset):\n",
    "    def __init__(self, preproc, fnames, labels, seq, mixup_alpha=MIXUP_ALPHA, is_training=True,\n",
    "                 desired_length=128, no_labels=False, no_fnames=True, do_augmentation=True, df=None):\n",
    "        super().__init__()\n",
    "        self.preproc = preproc\n",
    "        self.fnames = fnames\n",
    "        self.labels = labels\n",
    "        self.seq = seq\n",
    "        self.mixup_alpha = mixup_alpha\n",
    "        self.is_training = is_training\n",
    "        self.desired_length = desired_length\n",
    "        self.no_labels = no_labels\n",
    "        self.no_fnames = no_fnames\n",
    "\n",
    "        self.transforms = transforms.ToTensor()\n",
    "        self.no_fnames = no_fnames\n",
    "        self.do_augmentation = do_augmentation\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def crop_img(self, image, crop=None):\n",
    "        time_dim = image.shape[1]\n",
    "        diff = time_dim - self.desired_length\n",
    "        if diff > 0:\n",
    "            if crop is None:\n",
    "                crop = random.randint(0, diff)\n",
    "            image = image[:, crop:crop + self.desired_length]\n",
    "        elif diff < 0:\n",
    "            tmp = np.zeros([image.shape[0], self.desired_length, *image.shape[2:]],\n",
    "                           dtype=image.dtype)\n",
    "            if crop is None:\n",
    "                crop = random.randint(0, -diff)\n",
    "            tmp[:, crop:crop + image.shape[1]] = image\n",
    "            image = tmp\n",
    "        else:\n",
    "            crop = 0\n",
    "        return image, crop\n",
    "    \n",
    "    def prep_img(self, image):\n",
    "        if self.is_training and self.do_augmentation:\n",
    "            image = self.seq.augment_image(image)\n",
    "        image = self.transforms(image)\n",
    "        if self.is_training and self.do_augmentation:\n",
    "            image = augment_spectrogram(image)\n",
    "        return image.div_(255)\n",
    "    \n",
    "    def preprep_img(self, image):\n",
    "        if image.shape[0] == 1:\n",
    "            image = np.tile(image, [3, 1, 1])\n",
    "        image = np.transpose(image, [1, 2, 0])\n",
    "        return image\n",
    "    \n",
    "    def get_pd(self, idx):\n",
    "        c0, c1, f0, f1, mixup_p, y = self.df[idx]\n",
    "        image = self.preproc[f0]\n",
    "        image = self.preprep_img(image)\n",
    "        image, crop = self.crop_img(image, c0)\n",
    "        if mixup_p < 0.98:  # save compute when mixup barely has effect\n",
    "            oth_image = self.preproc[f1]\n",
    "            oth_image = self.preprep_img(oth_image)\n",
    "            oth_image, oth_crop = self.crop_img(oth_image, c1)\n",
    "            image = mixup_p * image + (1 - mixup_p) * oth_image\n",
    "            image = image.round().astype(np.uint8)\n",
    "        image = self.prep_img(image)\n",
    "        return image, y\n",
    "            \n",
    "    def __getitem__(self, idx):\n",
    "        if self.df is not None:\n",
    "            return self.get_pd(idx)\n",
    "        fname = self.fnames[idx]\n",
    "        oth_fname = ''\n",
    "        image = self.preproc[fname]\n",
    "        image = self.preprep_img(image)\n",
    "        if not self.no_labels:\n",
    "            label = self.labels[idx]\n",
    "        image, crop = self.crop_img(image)\n",
    "        crops = [crop, -99999]\n",
    "        mixup_p = 1.0\n",
    "        if self.is_training and self.mixup_alpha:\n",
    "            mixup_p = np.random.beta(self.mixup_alpha + 1, self.mixup_alpha)\n",
    "            if mixup_p < 0.98:  # save compute when mixup barely has effect\n",
    "                oth_image, oth_label, oth_fname = get_noisy_img_and_label(self.preproc)\n",
    "                oth_image = self.preprep_img(oth_image)\n",
    "                oth_image, oth_crop = self.crop_img(oth_image)\n",
    "                crops[-1] = oth_crop\n",
    "                image = mixup_p * image + (1 - mixup_p) * oth_image\n",
    "                image = image.round().astype(np.uint8)\n",
    "                label = label + (1 - mixup_p) * oth_label\n",
    "                label = np.clip(label, 0.0, 1.0)\n",
    "        image = self.prep_img(image)\n",
    "        ret = []\n",
    "        ret += [image]\n",
    "        if self.no_labels:\n",
    "            return tuple(ret)\n",
    "        ret += [torch.from_numpy(label).float()]\n",
    "        if self.no_fnames:\n",
    "            return tuple(ret)\n",
    "        ret += crops\n",
    "        ret += [fname, oth_fname]\n",
    "        ret += [mixup_p]\n",
    "        return tuple(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = BATCH_SIZE\n",
    "test_batch_size = BATCH_SIZE * 2\n",
    "lr = LR\n",
    "lr_min = LR_MIN\n",
    "t_max = T_MAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FATTrainDataset(preproc, x_train, y_train, seq=seq, mixup_alpha=MIXUP_ALPHA, is_training=True)\n",
    "valid_dataset = FATTrainDataset(preproc, x_train_all, y_train_all, seq=seq, is_training=True, no_fnames=False, mixup_alpha=0.5)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=test_batch_size, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x, y, c0, c1, f0, f1, mix = valid_dataset[0]\n",
    "# df = [[c0, c1, f0, f1, mix, 'y']]\n",
    "# test_ds = FATTrainDataset(preproc, x_train_all, y_train_all, seq=seq, is_training=True, do_augmentation=False, df=df)\n",
    "# torch.all(test_ds[0][0] = x)  # True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        return param_group['lr']\n",
    "\n",
    "model = Classifier(num_classes=num_classes)\n",
    "model = model.cuda()\n",
    "optimizer = Adam(params=model.parameters(), lr=lr, amsgrad=False)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=t_max, eta_min=lr_min)\n",
    "criterion = nn.BCEWithLogitsLoss().cuda()\n",
    "model = nn.DataParallel(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "global_step = 0\n",
    "num_epochs = NUM_EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_interesting_epoch(epoch):\n",
    "    epoch = epoch + 1\n",
    "    if epoch // 10 % 2 == 1:\n",
    "        if epoch - (10 * (epoch // 10)) < 5:\n",
    "            if epoch > 88:\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "mb = master_bar(range(epoch, num_epochs))\n",
    "\n",
    "for epoch in mb:\n",
    "    start_time = time.time()\n",
    "    model.train()\n",
    "    avg_loss = 0.\n",
    "\n",
    "    for stuff in progress_bar(train_loader, parent=mb):\n",
    "        global_step += 1\n",
    "        if len(stuff) == 2:\n",
    "            x_batch, y_batch = [i.cuda() for i in stuff]\n",
    "            \n",
    "        preds = model(x_batch)\n",
    "        loss_train = criterion(preds, y_batch)\n",
    "        loss = loss_train\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_loss += loss_train.item() / len(train_loader)\n",
    "\n",
    "    do_val = is_interesting_epoch(epoch)\n",
    "\n",
    "    if do_val:\n",
    "        model.eval()\n",
    "        df = None\n",
    "        iterer = iter(valid_loader)\n",
    "        for _ in progress_bar(range(NUM_VAL_PREDS_PER_EPOCH), parent=mb):\n",
    "            x, y, c0, c1, f0, f1, mix = next(iterer)\n",
    "            preds = model(x.cuda()).detach().cpu()\n",
    "            df_this = pd.DataFrame([np.array(i) for i in [c0, c1, f0, f1, mix, preds]]).T\n",
    "            if df is None:\n",
    "                df = df_this\n",
    "            else:\n",
    "                df = pd.concat([df, df_this], 0)\n",
    "\n",
    "        df.columns = ['c0', 'c1', 'f0', 'f1', 'mix', 'y']\n",
    "        if os.path.exists(str(savedir / f'epoch{epoch}.csv')):\n",
    "            os.remove(str(savedir / f'epoch{epoch}.csv'))\n",
    "        df.to_hdf(savedir / f'epoch{epoch}.csv', 'data')\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    tboard_writer.add_scalar('metrics/avg_train_loss', avg_loss, epoch + 1)\n",
    "    tboard_writer.add_scalar('meta/lr', get_lr(optimizer), epoch + 1)\n",
    "    tboard_writer.add_scalar('meta/elapsed', elapsed, epoch + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p36'\n'",
   "language": "python",
   "name": "p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
